\documentclass[12pt, letterpaper, titlepage]{article}

\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{colorlinks = true, linkcolor = blue, citecolor=blue, urlcolor = blue}
\usepackage{natbib}
\usepackage{enumitem}
\usepackage{setspace}

\usepackage[pagewise]{lineno}
%\linenumbers*[1]
% %% patches to make lineno work better with amsmath
\newcommand*\patchAmsMathEnvironmentForLineno[1]{%
 \expandafter\let\csname old#1\expandafter\endcsname\csname #1\endcsname
 \expandafter\let\csname oldend#1\expandafter\endcsname\csname end#1\endcsname
 \renewenvironment{#1}%
 {\linenomath\csname old#1\endcsname}%
 {\csname oldend#1\endcsname\endlinenomath}}%
\newcommand*\patchBothAmsMathEnvironmentsForLineno[1]{%
 \patchAmsMathEnvironmentForLineno{#1}%
 \patchAmsMathEnvironmentForLineno{#1*}}%

\AtBeginDocument{%
 \patchBothAmsMathEnvironmentsForLineno{equation}%
 \patchBothAmsMathEnvironmentsForLineno{align}%
 \patchBothAmsMathEnvironmentsForLineno{flalign}%
 \patchBothAmsMathEnvironmentsForLineno{alignat}%
 \patchBothAmsMathEnvironmentsForLineno{gather}%
 \patchBothAmsMathEnvironmentsForLineno{multline}%
}

% control floats
\renewcommand\floatpagefraction{.9}
\renewcommand\topfraction{.9}
\renewcommand\bottomfraction{.9}
\renewcommand\textfraction{.1}
\setcounter{totalnumber}{50}
\setcounter{topnumber}{50}
\setcounter{bottomnumber}{50}

\newcommand{\jy}[1]{\textcolor{blue}{JY: #1}}
\newcommand{\eds}[1]{\textcolor{red}{EDS: (#1)}}


\title{Time Series Length at Which Block Bootstrapping is Effective for Estimation of Variance}

\author{Mathew Chandy\\
%   \href{mailto:mathew.chandy@uconn.edu}
% {\nolinkurl{mathew.chandy@uconn.edu}}\\
  Jun Yan\\[1ex]
  Department of Statistics, University of Connecticut\\
}
\date{}

\begin{document} 
\maketitle

\doublespace

\begin{abstract}
Block bootstrapping is a method that can be used for estimating a parameter of a time
series. It involves splitting a series into blocks (in order to account for the time
factor) and re-sampling the blocks to create many new bootstrapped time series.
This method becomes more effective as the length of the time series increases. 
The question for this study is how does one determine at what length the block
bootstrap method stops being effective to estimate a parameter of a time
series.

\bigskip
\noindent\sc{Keywords}:
block bootstrap;
\end{abstract}

\section{Introduction}
\label{sec:intro}

Block bootstrapping is a widely used method in Statistics. The concept for block 
bootstrapping was developed independently by \citet{hall1985resampling}, \citet{carlstein1986use}, and 
\citet{kunsch1989jackknife}. \citet{radovanov2014comparison} It has been applied to a variety of 
different fields such 
as econometrics \citep{mackinnon2006bootstrap} and meteorology \citep{varga2017generalised}. It can be used for 
situations in which there is temporal dependence, and the goal is the estimation or testing a hypothesis about a parameter. Assuming that the sample is infinitely 
large, the method will work perfectly. However, for a finite sample size, the method will 
not work as well as expected. \citet{hesterberg2015teachers} notes that while intervals based on the percentiles from nonparametric bootstrapping are more accurate than t-intervals for larger sample sizes, they are less accurate for smaller sample sizes. In the context of planning an applied 
statistical procedure, for which a large sample size is not always practical, it may be helpful to know at which sample size the method stops working at an acceptable level. 
The goal of this study is to find a threshold or range of sample sizes at which block bootstrap 
is no longer an effective method for estimating variance of a parameter.

\citet{nevitt2001performance} find that a sample size of 200-1000 is usually sufficient for estimation using the bootstrap method (simple resampling with no blocks involved). However, block bootstrapping is a different situation altogether because the sample is split into blocks.

\citet{goncalves2005bootstrap} found that standard error estimates from block bootstrapping small 
samples 
may be significantly more accurate than inference from closed-form asymptotic estimates. That study focused on the estimation of a parameter within the context of linear regression. Still, the block bootstrap percentile confidence intervals under covered even for n = 1024. This study aims to find how small the sample size can be for time series (which has a dependence factor which can be compared to that of a linear regression) in order for the coverage rate to be close to the confidence level.

For this study, many block bootstrap simulations were conducted with RStudio. At the base
level, we are block-bootstrapping an auto-regressive process with true mean 0, and some AR(1) coefficient.
Bootstrapping is the term for creating new samples of the same size by re-sampling from
the original sample with replacement. Estimates of two parameters (the mean and the AR(1) coefficient) from many bootstrapped samples are used to create a
distribution to estimate the parameter and its variance. This works well for samples
that are do not have a dependence factor. However, for a time series such as an auto-regressive process,
a different procedure is required to account for the time dependence. In such a case,
the series is split into blocks that can overlap (moving block bootstrap) or not(non-moving block bootstrap). These blocks are then re-sampled to create a new
bootstrapped time series sample. 

In our experiment, we find the mean and auto-correlation function estimatesof a 1000 block-bootstrapped time series, 
and create 95\% confidence intervals of these paramters We replicate this 1000 times, 
and record the proportion of confidence intervals that recover the true known parameter 
(coverage rate). We are effectively observing how successful the bootstrapping process
is at estimating a parameter and its variance. The key variable being observed was n, 
the length of the time series, or the size of the sample. It is known that as n
increases, block bootstrapping will become a less accurate method for estimation
(the coverage rates will decrease). The question is at what range of n values does this
start to become a problem and what range of n values is necessary to reach a coverage rate of 95\%.

In this experiment, there are certain factors that are expected to affect the coverage
rates. As the Auto-Regressive (AR) coefficient (the time dependence) of the time series 
increases,
we expect the coverage rates of the confidence intervals to decrease.
The coverage rates are also affected by the size of the blocks - more specifically,
how the size of the blocks (l) relates to the size of the time series (n) - 
and whether or not they overlap. It is known that as the size of the time series 
increases, the optimal block length should increase, and the ratio of the block length to 
the time series length should decrease. l = n$^{1/3}$ is typically considered the optimal 
block length according to asymptotic theory. \citep{buhlmann1999block} Simulations were conducted using this optimal function of l = n$^{1/3}$. 

In order to solve the question of what n is necessary for effective block bootstrapping,
while still accounting for all these factors, the simulations were repeated for
various combinations of AR coefficients, block length functions, and non-moving vs moving method. For each of these combinations, coverage rates were recorded for a wide range of sample sizes.

\section{Review of Block Bootstrap}
\label{sec:blkbootreview}

Block bootstrapping is a method that can be applied to a time series (or any sample of data for that matter) to estimate a parameter and its variance. Suppose that a sample of size n of a time series is given. In regular bootstrap procedure, the new sample of the same size as the original would just be created by resampling observations with replacement. In the case of a time series, in order to account for the temporal dependence, the time series can be split into blocks, typically of the same size. The block should be of size l large enough to include time dependence, yet small enough to include some variance. As n increases, an ideal l should also increase, but the ratio of l to n should decrease. To achieve this, l is often assigned a value as a function of n. A common function that is considered the best by much previous literature is l = n$^{1/3}$. However not all n sizes are perfect squares, and l must be a whole number, so the ceiling of this function must be used. A bootstrapped sample is created by taking a sample of n / l blocks with replacement to create a new series of size n. The designer of the study can choose whether the blocks overlap or not. If the blocks can never overlap, it is called a non-moving block bootstrap. In this case, the original sample is split evenly into n / l blocks, and the same number of blocks is sampled without replacement to create a bootstrapped sample. If the blocks do overlap, it is called a moving block bootstrap. n / l samples are taken randomly from the original sample, but they do not have to be from a set of evenly spaced blocks. An estimate of the parameter is computed from the bootstrapped sample. This procedure can be repeated many times (typically 1000) to create a sampling distribution of the estimator. Using this distribution of estimates, a 1 - $\alpha$/2 \% confidence interval for the parameter can be created using the $\alpha$/2 and 1 - $\alpha$/2 percentiles.

\section{Simulation Study Design}
\label{sec:simdesign}

The central objective of the study was to assess what sample size is necessary for the the block bootstrap method to estimate a parameter of an autoregressive process. The method will work better as the sample size goes to infinity, but the goal is to see what is the smallest sample size that is acceptable. The sample size is acceptable if many 1 - $\alpha$/2 confidence intervals for that sample size recover the parameter at a rate of 1 - $\alpha$/2. In the previous section, the procedure for creating a confidence interval of a parameter using the block bootstrap method is described. This process is applied to a simulation of an autoregressive integrated moving average (ARIMA) process to create a confidence interval of a certain parameter (could be the mean or the AR(1) coefficient). R has a built in ARIMA simulation which allows you to set the mean, AR(1) coefficient, and the standard deviation of the error term. Using the equation below, the standard deviation of the error term can be set so that the standard deviation of Y is constant (0.1, Variance = 0.01). 

\[ \sigma_{x}^{2}=\sigma_{\eta}^{2}/\left( 1-\phi^2 \right)\]
\[\sigma_{\eta}=\sqrt{\sigma_{x}^{2}*\left( 1-\phi^2 \right)}\]

For all simulation studies, the mean can be kept at 0, but the AR(1) Coefficient is the main factor that makes block bootstrap less effective, so its impact on the method's performance should be analyzed. For a certain variation of the ARIMA process, a block bootstrap 95\% confidence interval for a sample of length 32 is replicated 4000 times. For each individual confidence interval, it can be recorded whether or not the interval includes the true parameter. The coverage rate, or the proportion of intervals that include the true parameter, can then be recorded. If the parameter and its variance are being properly estimated by the block bootstrap, the coverage rate should reflect this by being close to the confidence level of 95\%. If this is not the case, the method is not working as well as it should. The width of the confidence interval for each replication is dependent on the variance of the parameter of the time series. If the interval is on average not wide enough to capture the parameter at the expected rate of 95\%, it indicates that the variance of the parameter (which will be estimated from the standard error of the parameter estimates from the bootstrapped samples) will be underestimated. If the interval is too wide and captures the parameter at a rate above 95\%, it indicates that the variance of the parameter will be overestimated. Since the coverage rate is a proportion based on many replication of independent Bernoulli outcomes, a 95\% confidence interval of the coverage rate at that sample size can also be created. We can be 95\% confident that the true expected coverage rate is included in this interval, so if .95 is included in the interval, this indicates that the block bootstrap method is working well. Once the simulation is done for this sample size, the process can be run again with a sample twice as big. This can be continued until the method is determined to be working acceptably (.95 is included within the confidence interval of the coverage rate).

\section{Methods}
\label{sec:methods}

12 variations of simulation studies were analyzed based on factors that might affect the results of the block bootstrap method. Simulation studies were conducted for an autoregressive process with AR = 0, an autoregressive process with AR = 0.2, and an autoregressive process with AR = 0.4. For each of these AR(1) coefficient values, separate simulation studies were conducted for the mean and AR(1) coefficient. For each of these variations, the non-moving block bootstrap method as well as the moving block bootstrap method were applied to estimate the respective parameter. 

The goal was to determine what range of sample sizes was acceptable for each of these variations of simulation studies.



 

\section{Results}
\label{sec:results}

As the AR(1) coefficient increases, it was found unsurprisingly that a large sample size was needed for the block bootstrap method to work. When the target for estimation was the mean of the process, moving block bootstrap generally had a similar performance to non-moving block bootstrap. However when the target for estimation was the AR(1) coefficient of the process, moving block bootstrap noticeably recovered the parameter at a greater rate than non-moving block bootstrap. When the target was the mean and theta was more than 0, the coverage rate was generally much higher than that for when the target was the AR(1) coefficient. However when theta was 0, the AR(1) coefficient was recovered at a greater rate than the mean. 



\begin{figure}[tbp]
\caption{The figure below shows results for block bootstrap estimation when theta is 0. When the target was the mean and the moving method was used, the coverage rate confidence interval included .95 when the sample length was 512, indicating that even for a sample with no temporal dependence, a very large sample length of around 500 is necessary to get an accurate estimation of the mean. Similarly, when the target was the mean and the non-moving method was used, the coverage rate confidence interval included .95 when the sample length was 512, showing that a sample size of around 500 is necessary for good block bootstrap estimation. When the target was the AR(1) coefficient and the moving method was used, the parameter was over-covered - all of the coverage rate confidence interval lower bounds were greater than .95 - for all sample sizes that were observed (32, 64, 128, 256, and 512). This indicates that the variance of the parameter is being overestimated. When the target was the AR(1) coefficient and the non-moving method was used, the parameter was under-covered when the sample length was 32 and slightly over-covered when the sample length was 256. For sample lengths 64, 128, and 512, the non-moving method recovered the parameter well.}
  \centering
  \includegraphics[width=\textwidth]{theta_0}
  \caption{}
  \label{fig:theta_0}
\end{figure}

\begin{figure}[tbp]
\caption{The figure below shows results for block bootstrap estimation when theta is 0.2. When the target was the mean and the moving method was used, the coverage rate confidence interval included .95 when the sample length was 2048 and 4096, indicating that even for a sample with relatively low temporal dependence, a very large sample of around 2000 is necessary to get an accurate estimation of the mean. Similarly, when the target was the mean and the non-moving method was used, the coverage rate confidence interval included .95 when the sample length was 2048 and 4096, showing that a sample size of around 2000 is necessary for good block bootstrap estimation. When the target was the AR(1) coefficient, for both methods, the parameter was under-covered for sample lengths as large as 4096, although the moving method appeared to perform better for all sample sizes. }
  \centering
  \includegraphics[width=\textwidth]{theta_0.2}
  \caption{}
  \label{fig:theta_0.2}
\end{figure}

\begin{figure}[tbp]
\caption{The figure below shows results for block bootstrap estimation when theta is 0.4. When the target was the mean, for both methods, the coverage rate was under-covered for sample sizes as large as 8192. When the target was the AR(1) coefficient, for both methods, the parameter was under-covered for sample lengths as large as 4096, although the moving method appeared to perform better for smaller sample sizes. }
  \centering
  \includegraphics[width=\textwidth]{theta_0.4}
  \caption{}
  \label{fig:theta_0.4}
\end{figure}

\section{Discussion}
\label{sec:discuss}

This study finds that as the AR coefficient increases, the sample size necessary for effective block bootstrap estimation must be larger. When implementing the block bootstrap method to estimate the mean of an autoregressive process, the non-moving method and moving method perform about the same. However, when estimating the AR(1) coefficient, the non-moving method performs noticeably worse than the moving method, which still covers the coefficient poorly when theta is greater than 0.



\bibliographystyle{chicago}
\bibliography{citations}[tp]


\end{document}